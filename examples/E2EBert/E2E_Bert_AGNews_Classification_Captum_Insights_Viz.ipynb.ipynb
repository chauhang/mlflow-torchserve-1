{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Captum Visual Insights for Finetuned AG News Classification  model from the BERT Pretrained Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook helps you to get started with the Captum Insights. In this example, we have finetuned the BERT pre-trained model using feature extraction for AG News classification which classifies the given input in one of the following classes (\"world\", \"Sports\", \"Business\", \"Sci/Tech\"). We have showcased that how we can visualize the word importances and attributions.We can visualize Captum Insights normally and making a request on torchserve as well as shown  in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from ts.torch_handler.base_handler import BaseHandler\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import visualization\n",
    "from news_classifier import BertNewsClassifier\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets give the input data point which we want to classifiy and want to see the captum insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This year business is good\n"
     ]
    }
   ],
   "source": [
    "data = {\"data\": [\"This year business is good\"]}\n",
    "text = data[\"data\"][0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get all the necessary utility function and input files need to classify the input data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bert_outputs(model_bert, embedding_input, attention_mask=None, head_mask=None):\n",
    "    if attention_mask is None:\n",
    "        attention_mask = torch.ones(embedding_input.shape[0], embedding_input.shape[1]).to(embedding_input)\n",
    "\n",
    "    extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "    extended_attention_mask = extended_attention_mask.to(dtype=next(model_bert.parameters()).dtype) # fp16 compatibility\n",
    "    extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "\n",
    "    if head_mask is not None:\n",
    "        if head_mask.dim() == 1:\n",
    "            head_mask = head_mask.unsqueeze(0).unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "            head_mask = head_mask.expand(model_bert.config.num_hidden_layers, -1, -1, -1, -1)\n",
    "        elif head_mask.dim() == 2:\n",
    "            head_mask = head_mask.unsqueeze(1).unsqueeze(-1).unsqueeze(-1)  # We can specify head_mask for each layer\n",
    "        head_mask = head_mask.to(dtype=next(model_bert.parameters()).dtype) # switch to fload if need + fp16 compatibility\n",
    "    else:\n",
    "        head_mask = [None] * model_bert.config.num_hidden_layers\n",
    "\n",
    "    encoder_outputs = model_bert.encoder(embedding_input,\n",
    "                                         extended_attention_mask,\n",
    "                                         head_mask=head_mask)\n",
    "    sequence_output = encoder_outputs[0]\n",
    "    pooled_output = model_bert.pooler(sequence_output)\n",
    "    outputs = (sequence_output, pooled_output,) + encoder_outputs[1:]\n",
    "    return outputs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertNewsClassifier(\n",
       "  (train_acc): Accuracy()\n",
       "  (val_acc): Accuracy()\n",
       "  (test_acc): Accuracy()\n",
       "  (bert_model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (drop): Dropout(p=0.2, inplace=False)\n",
       "  (fc1): Linear(in_features=768, out_features=512, bias=True)\n",
       "  (out): Linear(in_features=512, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir =os.getcwd()\n",
    "# Read model serialize/pt file\n",
    "model_pt_path = os.path.join(model_dir, \"state_dict.pth\")\n",
    "# Read model definition file\n",
    "VOCAB_FILE = os.path.join(model_dir, \"bert_base_uncased_vocab.txt\")\n",
    "if not os.path.isfile(VOCAB_FILE):\n",
    "    raise RuntimeError(\"Missing the vocab file\")\n",
    "\n",
    "class_mapping_file = os.path.join(model_dir, \"class_mapping.json\")\n",
    "state_dict = torch.load(model_pt_path, map_location=device)\n",
    "model = BertNewsClassifier()\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class AGNewsmodelWrapper(nn.Module):\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        super(AGNewsmodelWrapper, self).__init__()\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, embeddings):        \n",
    "        outputs =compute_bert_outputs(self.model.bert_model,embeddings)\n",
    "        pooled_output = outputs[1]\n",
    "        output = F.relu(self.model.fc1(pooled_output))\n",
    "        output = self.model.drop(output)\n",
    "        output = self.model.out(output)\n",
    "        print(\"shape of final output\",output.shape)\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we first create an IntegratedGradients object, providing the model object.\n",
    "ag_model_wrapper = AGNewsmodelWrapper(model)\n",
    "ig_1 = IntegratedGradients(ag_model_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We get the inputs ids and embedings to pass on the model for predictions\n",
    "tokenizer= BertTokenizer(VOCAB_FILE)\n",
    "ag_model_wrapper.eval()\n",
    "ag_model_wrapper.zero_grad()\n",
    "\n",
    "input_ids= torch.tensor([tokenizer.encode(text, add_special_tokens=True)])\n",
    "input_embedding_test = ag_model_wrapper.model.bert_model.embeddings(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 768])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embedding_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of final output torch.Size([1, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-4.2157, -4.3001,  3.1976,  1.3784]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the ouput and making the prediction\n",
    "preds= ag_model_wrapper(input_embedding_test)\n",
    "out = np.argmax(preds.cpu().detach(), axis=1)\n",
    "out =(out.item())\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85961217"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets define the score function to get the probabilty for predicted class\n",
    "def score_func(o):\n",
    "    output = F.softmax(o, dim=1)\n",
    "    pre_pro= np.max(output.detach().numpy())\n",
    "    return pre_pro\n",
    "\n",
    "score_func(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 768])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can create a reference baselines for pass in to the IG object.\n",
    "text_ref =\"PAD PAD PAD PAD PAD\"\n",
    "input_id_ref= torch.tensor([tokenizer.encode(text_ref, add_special_tokens=True)])\n",
    "input_embedding_ref = ag_model_wrapper.model.bert_model.embeddings(input_id_ref)\n",
    "input_embedding_ref.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of final output torch.Size([500, 4])\n",
      "shape of final output torch.Size([1, 4])\n",
      "shape of final output torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "#Lets calculate the IG attributions attributing towards for target class 1 \n",
    "attributions, delta = ig_1.attribute(input_embedding_test, n_steps=500, return_convergence_delta=True, target=1,baselines =input_embedding_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'this', 'year', 'business', 'is', 'good', '[SEP]']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0].numpy().tolist())    \n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets visulize the captum insights below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_data_records_base=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_attributions_to_visualizer(attributions, tokens, pred_prob, pred_class, true_class,attr_class, delta, vis_data_records):\n",
    "    attributions = attributions.sum(dim=2).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    attributions = attributions.detach().numpy()\n",
    "    \n",
    "    # storing couple samples in an array for visualization purposes\n",
    "    vis_data_records.append(visualization.VisualizationDataRecord(\n",
    "                            attributions,\n",
    "                            pred_prob,\n",
    "                            pred_class,\n",
    "                            true_class,\n",
    "                            attr_class,\n",
    "                            attributions.sum(),       \n",
    "                            tokens,\n",
    "                            delta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_attributions_to_visualizer(attributions, tokens, score_func(preds), out, 2,1, delta, vis_data_records_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<captum.attr._utils.visualization.VisualizationDataRecord at 0x7f894d105d60>]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_data_records_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>2</b></text></td><td><text style=\"padding-right:2em\"><b>2 (0.86)</b></text></td><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>-0.34</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 73%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> year                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> business                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 68%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> good                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>2</b></text></td><td><text style=\"padding-right:2em\"><b>2 (0.86)</b></text></td><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>-0.34</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 73%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> year                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> business                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 68%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> good                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualization.visualize_text(vis_data_records_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making explain request using torchserve  and visulize the captum insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the mar file for the AG News classification model and place the artefacts from where you can serve the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "None deployment news_classification_test/1.0 is created\r\n"
     ]
    }
   ],
   "source": [
    "!mlflow deployments create -t torchserve -m state_dict.pth --name news_classification_test -C \"VERSION=1.0\" -C \"MODEL_FILE=news_classifier.py\" -C \"HANDLER=news_classifier_handler.py\" -C \"EXTRA_FILES=class_mapping.json,bert_base_uncased_vocab.txt,wrapper.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow deployments explain --name news_classification_test --target torchserve --input-path input.json --output-path output.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets read the output json created by the above step for visulization purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "input_file=open('./output.json', 'r')\n",
    "input_json = json.load(input_file)\n",
    "input_json =json.loads(input_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'words': ['[CLS]', 'this', 'year', 'business', 'is', 'good', '[SEP]'], 'importances': [0.08991567404246674, -0.14802681270486315, -0.41718128976163793, 0.2256927237290009, -0.3142787171026753, -0.10879051751774257, 0.796504432809415], 'delta': 1.3522652356019162}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(input_json)\n",
    "print(type(input_json))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of words and importances 7 7\n"
     ]
    }
   ],
   "source": [
    "attributions = input_json['importances']\n",
    "words = input_json['words']\n",
    "delta = input_json['delta']\n",
    "\n",
    "print(\"len of words and importances\",len(attributions),len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions = torch.tensor(attributions)\n",
    "pred_prob = score_func(preds)\n",
    "pred_class = out\n",
    "true_class = 2\n",
    "attr_class =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_data_records =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_data_records.append(visualization.VisualizationDataRecord(\n",
    "                            attributions,\n",
    "                            pred_prob,\n",
    "                            pred_class,\n",
    "                            true_class,\n",
    "                            attr_class,\n",
    "                            attributions.sum(),       \n",
    "                            tokens,\n",
    "                            delta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>2</b></text></td><td><text style=\"padding-right:2em\"><b>2 (0.86)</b></text></td><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>0.12</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(0, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> year                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> business                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> good                    </font></mark><mark style=\"background-color: hsl(120, 75%, 61%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>2</b></text></td><td><text style=\"padding-right:2em\"><b>2 (0.86)</b></text></td><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>0.12</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(0, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> year                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> business                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> good                    </font></mark><mark style=\"background-color: hsl(120, 75%, 61%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualization.visualize_text(vis_data_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython.display\n",
    "IPython.display.Image(filename=\"AGNews_Captum_Insights.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "02c84e89a0284804b4fc06bec870f8a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_67099009e09f4a80b627c8bafb0340f8",
       "max": 28,
       "style": "IPY_MODEL_198f8bb0d894427a871b49703c696efd",
       "value": 28
      }
     },
     "198f8bb0d894427a871b49703c696efd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "1e02e02a329545519649b51aa733276c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_6d6b74ceefec40fd95f0c14b0de80cbd",
       "style": "IPY_MODEL_22d3c8168cce4cf7b5e3470245c7d736",
       "value": "Downloading: 100%"
      }
     },
     "22d3c8168cce4cf7b5e3470245c7d736": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "232bf73daa9746bda241adc11d23be45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_cebe6bac285b4737847592da351d8b2a",
       "style": "IPY_MODEL_8a83cb139613484f9525b57a5f6608b3",
       "value": " 466k/466k [00:02&lt;00:00, 204kB/s]"
      }
     },
     "382d7459914248ce921c86d3cd321381": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_3ac50eb773264c4297979069925b0fbf",
        "IPY_MODEL_02c84e89a0284804b4fc06bec870f8a8",
        "IPY_MODEL_69233443a00b4ed4b8e872b31db50e9b"
       ],
       "layout": "IPY_MODEL_51a3ec3203ad4486af126a94dd2773ed"
      }
     },
     "3ac50eb773264c4297979069925b0fbf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_fa60245a05394190b5ec49f6c86343c0",
       "style": "IPY_MODEL_3dddbe5dcf394eee99f459ac890e7da4",
       "value": "Downloading: 100%"
      }
     },
     "3dddbe5dcf394eee99f459ac890e7da4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4c3de2869899423ebd214153464e3030": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "51a3ec3203ad4486af126a94dd2773ed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "67099009e09f4a80b627c8bafb0340f8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "69233443a00b4ed4b8e872b31db50e9b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_99886d58e1864fe799b2cfa32d35e77e",
       "style": "IPY_MODEL_a17f01faa69c4c52919b78c84d99e005",
       "value": " 28.0/28.0 [00:00&lt;00:00, 576B/s]"
      }
     },
     "6d6b74ceefec40fd95f0c14b0de80cbd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "73292c28aa3f484bb785335f02b95509": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_1e02e02a329545519649b51aa733276c",
        "IPY_MODEL_9eac59e6304f4792828a393204cec6f6",
        "IPY_MODEL_232bf73daa9746bda241adc11d23be45"
       ],
       "layout": "IPY_MODEL_b6163a7dfcdf4083a71a7fd2bb483783"
      }
     },
     "8a83cb139613484f9525b57a5f6608b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "954d4966dc334bef9bc97ebf588979ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "99886d58e1864fe799b2cfa32d35e77e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9eac59e6304f4792828a393204cec6f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_954d4966dc334bef9bc97ebf588979ce",
       "max": 466062,
       "style": "IPY_MODEL_4c3de2869899423ebd214153464e3030",
       "value": 466062
      }
     },
     "a17f01faa69c4c52919b78c84d99e005": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b6163a7dfcdf4083a71a7fd2bb483783": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cebe6bac285b4737847592da351d8b2a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fa60245a05394190b5ec49f6c86343c0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
